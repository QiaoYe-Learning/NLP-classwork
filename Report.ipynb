{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QiaoYe-Learning/NLP-classwork/blob/main/Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "563051e2-3cd3-4343-9b13-fa1b56c4075b",
      "metadata": {
        "id": "563051e2-3cd3-4343-9b13-fa1b56c4075b"
      },
      "source": [
        "# <center>NLP - Assignment_1 | Qiao Guanbo | G2406053H</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9b1014d-ab15-4eaa-bfe4-1c1a97f15d6f",
      "metadata": {
        "id": "c9b1014d-ab15-4eaa-bfe4-1c1a97f15d6f"
      },
      "source": [
        "### 1. Conduct experiments with different optimizers: SGD, Adam, Adagrad and record the experimental results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51365701-5499-47d4-acae-4db94a573d47",
      "metadata": {
        "id": "51365701-5499-47d4-acae-4db94a573d47"
      },
      "source": [
        "**<center>Model test results</center>**\n",
        "\n",
        "| Model | Epoches | Optimizer  | Test Loss | Test Accuracy |\n",
        "| :---: | :---: | :--------: | :-------: | :-----------: |\n",
        "|  RNN  |  20   |   SGD   |   0.683   |    56.01%     |\n",
        "|  RNN  |  20   |  Adam   |   0.683   |    66.69%     |\n",
        "|  RNN  |  20   | Adagrad |   0.702   |    67.78%     |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11cde691-c858-46e9-8b7b-c111e6b0b480",
      "metadata": {
        "id": "11cde691-c858-46e9-8b7b-c111e6b0b480"
      },
      "source": [
        "### 2. Use Adam optimizer, conduct experiments with different number of epochs: 5, 10, 20, and 50."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83a3949e-d18c-42e7-9988-ca5a87d5a2a9",
      "metadata": {
        "id": "83a3949e-d18c-42e7-9988-ca5a87d5a2a9"
      },
      "source": [
        "**<center>Model test results</center>**\n",
        "\n",
        "| Model | Epoches | Optimizer | Test Loss | Test Accuracy |\n",
        "| :---: | :-----: | :-------: | :-------: | :-----------: |\n",
        "|  RNN  |    5    |   Adam    |   0.655   |    61.16%     |\n",
        "|  RNbN  |   10    |   Adam    |   0.631   |    64.19%     |\n",
        "|  RNN  |   20    |   Adam    |   0.683   |    66.69%     |\n",
        "|  RNN  |   50    |   Adam    |   0.871   |    71.02%     |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e00f474d-d0fc-46db-985e-c1913600a5d1",
      "metadata": {
        "id": "e00f474d-d0fc-46db-985e-c1913600a5d1"
      },
      "source": [
        "### 3. Use Adam optimizer, 50 epochs and randomly initialized embeddings, run the experiments with the following models:\n",
        "   - One-layer feed forward neural network, hidden dimension is 500.\n",
        "   - Two-layer feed forward neural network, hidden dimensions are 500 and 300.\n",
        "   - Three-layer feed forward neural network, hidden dimensions are 500, 300, and 200.\n",
        "   - CNN model (using three feature maps with the sizes of feature map are 1, 2, and 3).\n",
        "   - LSTM model\n",
        "   - Bi-LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de55b419-23e6-4e41-a881-16905ea9bbef",
      "metadata": {
        "id": "de55b419-23e6-4e41-a881-16905ea9bbef"
      },
      "source": [
        "**<center>Model test results</center>**\n",
        "\n",
        "|  Model            | Epoches | Test Loss | Test Accuracy |\n",
        "| :---------------: | :---: | :-------: | :-----------: |\n",
        "| One-Layer FFNN [500]             |  50   |   0.341   |    86.56%|\n",
        "| Two-Layer FFNN [500,300]         |  50   |   0.363   |    85.02%|\n",
        "| Three-Layer FFNN [500,300,200]   |  50   |   0.359   |    84.42%|\n",
        "| CNN_Kernal Size = 1 |  50   |   0.319   |    86.58%|\n",
        "| CNN_Kernal Size = 2 |  50   |   0.313   |    86.92%|\n",
        "| CNN_Kernal Size = 3 |  50   |   0.318   |    86.16%|\n",
        "|         LSTM        |  50   |   0.385   |    83.67%|\n",
        "|       Bi-LSTM       |  50   |   0.402   |    82.21%|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c717591a-24aa-4c41-ae9f-a4499d56d0c0",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "c717591a-24aa-4c41-ae9f-a4499d56d0c0"
      },
      "source": [
        "## <center>Appendix(Running Result)</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1c6d6d-46ce-4684-b135-1af64a5ccfb5",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "5f1c6d6d-46ce-4684-b135-1af64a5ccfb5"
      },
      "source": [
        "### 1. Conduct experiments with different optimizers: SGD, Adam, Adagrad and record the experimental results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dfe979b-bc60-4b00-887c-d6aac00359f9",
      "metadata": {
        "id": "9dfe979b-bc60-4b00-887c-d6aac00359f9"
      },
      "source": [
        "| Epoch |   Optimizer    | Epoch Time | Val. Acc | Train Loss | Train Acc | Val. Loss |\n",
        "| :---: | :----------------: | :--------: | :------: | :--------: | :-------: | :-------: |\n",
        "|  01   | SGD-Epoches_20 |     5s     |  50.64%  |   0.695    |  50.21%   |   0.694   |\n",
        "|  02   | SGD-Epoches_20 |     3s     |  51.02%  |   0.693    |  51.74%   |   0.694   |\n",
        "|  03   | SGD-Epoches_20 |     3s     |  51.18%  |   0.691    |  52.13%   |   0.693   |\n",
        "|  04   | SGD-Epoches_20 |     4s     |  51.39%  |   0.690    |  52.77%   |   0.692   |\n",
        "|  05   | SGD-Epoches_20 |     3s     |  51.60%  |   0.690    |  52.83%   |   0.692   |\n",
        "|  06   | SGD-Epoches_20 |     3s     |  51.88%  |   0.689    |  53.21%   |   0.691   |\n",
        "|  07   | SGD-Epoches_20 |     3s     |  52.26%  |   0.688    |  53.57%   |   0.691   |\n",
        "|  08   | SGD-Epoches_20 |     3s     |  52.79%  |   0.687    |  53.82%   |   0.691   |\n",
        "|  09   | SGD-Epoches_20 |     3s     |  52.68%  |   0.687    |  54.10%   |   0.690   |\n",
        "|  10   | SGD-Epoches_20 |     3s     |  52.93%  |   0.686    |  54.25%   |   0.689   |\n",
        "|  11   | SGD-Epoches_20 |     3s     |  53.36%  |   0.686    |  54.74%   |   0.689   |\n",
        "|  12   | SGD-Epoches_20 |     3s     |  53.32%  |   0.685    |  55.03%   |   0.689   |\n",
        "|  13   | SGD-Epoches_20 |     3s     |  53.45%  |   0.685    |  55.14%   |   0.688   |\n",
        "|  14   | SGD-Epoches_20 |     3s     |  53.58%  |   0.684    |  55.32%   |   0.688   |\n",
        "|  15   | SGD-Epoches_20 |     4s     |  53.87%  |   0.683    |  55.63%   |   0.687   |\n",
        "|  16   | SGD-Epoches_20 |     3s     |  54.04%  |   0.683    |  55.61%   |   0.687   |\n",
        "|  17   | SGD-Epoches_20 |     3s     |  54.28%  |   0.683    |  55.84%   |   0.687   |\n",
        "|  18   | SGD-Epoches_20 |     3s     |  54.60%  |   0.682    |  55.99%   |   0.686   |\n",
        "|  19   | SGD-Epoches_20 |     3s     |  54.63%  |   0.682    |  56.16%   |   0.686   |\n",
        "|  20   | SGD-Epoches_20 |     3s     |  54.78%  |   0.681    |  56.29%   |   0.685   |\n",
        "| :---: | :----------------: | :--------: | :--------: | :-------: | :-------: | :------: |\n",
        "|  01   | Adam-Epoches_20 |     3s     |   0.679    |  57.54%   |   0.727   |  54.96%  |\n",
        "|  02   | Adam-Epoches_20 |     4s     |   0.638    |  63.54%   |   0.648   |  61.59%  |\n",
        "|  03   | Adam-Epoches_20 |     3s     |   0.654    |  60.68%   |   0.661   |  58.55%  |\n",
        "|  04   | Adam-Epoches_20 |     3s     |   0.659    |  58.99%   |   0.692   |  52.24%  |\n",
        "|  05   | Adam-Epoches_20 |     3s     |   0.673    |  57.92%   |   0.667   |  58.51%  |\n",
        "|  06   | Adam-Epoches_20 |     3s     |   0.633    |  63.38%   |   0.661   |  59.38%  |\n",
        "|  07   | Adam-Epoches_20 |     3s     |   0.597    |  67.49%   |   0.695   |  60.07%  |\n",
        "|  08   | Adam-Epoches_20 |     3s     |   0.575    |  68.89%   |   0.674   |  64.15%  |\n",
        "|  09   | Adam-Epoches_20 |     4s     |   0.531    |  73.75%   |   0.619   |  65.99%  |\n",
        "|  10   | Adam-Epoches_20 |     3s     |   0.566    |  68.29%   |   0.685   |  53.90%  |\n",
        "|  11   | Adam-Epoches_20 |     3s     |   0.595    |  68.61%   |   0.664   |  61.30%  |\n",
        "|  12   | Adam-Epoches_20 |     3s     |   0.534    |  73.25%   |   0.675   |  63.02%  |\n",
        "|  13   | Adam-Epoches_20 |     3s     |   0.496    |  76.11%   |   0.631   |  68.49%  |\n",
        "|  14   | Adam-Epoches_20 |     3s     |   0.457    |  78.68%   |   0.656   |  68.06%  |\n",
        "|  15   | Adam-Epoches_20 |     3s     |   0.418    |  81.43%   |   0.670   |  67.53%  |\n",
        "|  16   | Adam-Epoches_20 |     4s     |   0.409    |  81.81%   |   0.700   |  59.09%  |\n",
        "|  17   | Adam-Epoches_20 |     3s     |   0.424    |  80.88%   |   0.700   |  67.61%  |\n",
        "|  18   | Adam-Epoches_20 |     3s     |   0.489    |  76.72%   |   0.694   |  59.77%  |\n",
        "|  19   | Adam-Epoches_20 |     4s     |   0.468    |  77.86%   |   0.727   |  63.64%  |\n",
        "|  20   | Adam-Epoches_20 |     3s     |   0.403    |  82.06%   |   0.673   |  67.34%  |\n",
        "| :---: | :----------------: | :--------: | :--------: | :-------: | :-------: | :------: |\n",
        "|  01   | Adagrad-Epoches_20 |     3s     |   0.322    |  86.64%   |   0.710   |  67.18%  |\n",
        "|  02   | Adagrad-Epoches_20 |     3s     |   0.307    |  87.71%   |   0.704   |  67.96%  |\n",
        "|  03   | Adagrad-Epoches_20 |     3s     |   0.311    |  87.21%   |   0.712   |  66.13%  |\n",
        "|  04   | Adagrad-Epoches_20 |     4s     |   0.302    |  87.85%   |   0.718   |  68.03%  |\n",
        "|  05   | Adagrad-Epoches_20 |     3s     |   0.296    |  88.11%   |   0.718   |  68.14%  |\n",
        "|  06   | Adagrad-Epoches_20 |     3s     |   0.296    |  88.03%   |   0.720   |  68.08%  |\n",
        "|  07   | Adagrad-Epoches_20 |     3s     |   0.292    |  88.20%   |   0.721   |  68.44%  |\n",
        "|  08   | Adagrad-Epoches_20 |     3s     |   0.290    |  88.39%   |   0.724   |  68.16%  |\n",
        "|  09   | Adagrad-Epoches_20 |     3s     |   0.288    |  88.54%   |   0.722   |  68.24%  |\n",
        "|  10   | Adagrad-Epoches_20 |     3s     |   0.288    |  88.52%   |   0.723   |  68.23%  |\n",
        "|  11   | Adagrad-Epoches_20 |     4s     |   0.286    |  88.66%   |   0.726   |  68.45%  |\n",
        "|  12   | Adagrad-Epoches_20 |     3s     |   0.294    |  88.11%   |   0.724   |  67.42%  |\n",
        "|  13   | Adagrad-Epoches_20 |     3s     |   0.286    |  88.66%   |   0.729   |  68.33%  |\n",
        "|  14   | Adagrad-Epoches_20 |     3s     |   0.282    |  88.77%   |   0.730   |  68.54%  |\n",
        "|  15   | Adagrad-Epoches_20 |     3s     |   0.282    |  88.61%   |   0.731   |  68.26%  |\n",
        "|  16   | Adagrad-Epoches_20 |     3s     |   0.281    |  88.79%   |   0.733   |  68.45%  |\n",
        "|  17   | Adagrad-Epoches_20 |     3s     |   0.282    |  88.66%   |   0.736   |  68.45%  |\n",
        "|  18   | Adagrad-Epoches_20 |     4s     |   0.280    |  88.85%   |   0.735   |  68.32%  |\n",
        "|  19   | Adagrad-Epoches_20 |     3s     |   0.278    |  88.92%   |   0.736   |  68.50%  |\n",
        "|  20   | Adagrad-Epoches_20 |     3s     |   0.276    |  89.03%   |   0.735   |  68.42%  |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bd23e6b-ec6b-4958-8d4b-5aab6f1fc9d2",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "9bd23e6b-ec6b-4958-8d4b-5aab6f1fc9d2"
      },
      "source": [
        "### 2. Adam optimizer, conduct experiments with different number of epochs: 5, 10, 20, and 50."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2308e713-f995-4c10-a435-33f01a089990",
      "metadata": {
        "id": "2308e713-f995-4c10-a435-33f01a089990"
      },
      "source": [
        "| Epoch |   Optimizer    | Epoch Time | Train Loss | Train Acc | Val. Loss | Val. Acc |\n",
        "| :---: | :------------: | :--------: | :--------: | :-------: | :-------: | :------: |\n",
        "|  01   | Adam-Epoches_5 |     4s     |   0.685    |  56.00%   |   0.689   |  52.93%  |\n",
        "|  02   | Adam-Epoches_5 |     3s     |   0.675    |  57.49%   |   0.679   |  55.85%  |\n",
        "|  03   | Adam-Epoches_5 |     3s     |   0.659    |  60.24%   |   0.695   |  51.47%  |\n",
        "|  04   | Adam-Epoches_5 |     3s     |   0.657    |  60.97%   |   0.640   |  64.19%  |\n",
        "|  05   | Adam-Epoches_5 |     4s     |   0.605    |  67.02%   |   0.655   |  60.99%  |\n",
        "| :---: | :-------------: | :--------: | :--------: | :-------: | :-------: | :------: |\n",
        "|  01   | Adam-Epoches_10 |     3s     |   0.684    |  56.22%   |   0.686   |  55.29%  |\n",
        "|  02   | Adam-Epoches_10 |     3s     |   0.669    |  58.41%   |   0.677   |  56.29%  |\n",
        "|  03   | Adam-Epoches_10 |     3s     |   0.684    |  54.48%   |   0.696   |  50.89%  |\n",
        "|  04   | Adam-Epoches_10 |     3s     |   0.693    |  52.41%   |   0.691   |  51.69%  |\n",
        "|  05   | Adam-Epoches_10 |     3s     |   0.693    |  51.80%   |   0.688   |  54.84%  |\n",
        "|  06   | Adam-Epoches_10 |     3s     |   0.686    |  53.86%   |   0.683   |  55.17%  |\n",
        "|  07   | Adam-Epoches_10 |     4s     |   0.674    |  57.13%   |   0.674   |  56.84%  |\n",
        "|  08   | Adam-Epoches_10 |     3s     |   0.655    |  59.90%   |   0.666   |  57.73%  |\n",
        "|  09   | Adam-Epoches_10 |     3s     |   0.626    |  63.73%   |   0.649   |  60.87%  |\n",
        "|  10   | Adam-Epoches_10 |     3s     |   0.580    |  68.49%   |   0.618   |  65.29%  |\n",
        "| :---: | :-------------: | :--------: | :--------: | :-------: | :-------: | :------: |\n",
        "|  01   | Adam-Epoches_50 |     3s     |   0.692    |  53.49%   |   0.689   |  52.29%  |\n",
        "|  02   | Adam-Epoches_50 |     4s     |   0.674    |  57.09%   |   0.671   |  57.14%  |\n",
        "|  03   | Adam-Epoches_50 |     3s     |   0.690    |  53.36%   |   0.693   |  51.39%  |\n",
        "|  04   | Adam-Epoches_50 |     3s     |   0.680    |  56.05%   |   0.667   |  58.67%  |\n",
        "|  05   | Adam-Epoches_50 |     4s     |   0.643    |  62.37%   |   0.669   |  59.88%  |\n",
        "|  06   | Adam-Epoches_50 |     3s     |   0.606    |  67.01%   |   0.601   |  68.62%  |\n",
        "|  07   | Adam-Epoches_50 |     3s     |   0.543    |  73.33%   |   0.610   |  65.73%  |\n",
        "|  08   | Adam-Epoches_50 |     3s     |   0.494    |  77.23%   |   0.565   |  71.27%  |\n",
        "|  09   | Adam-Epoches_50 |     3s     |   0.473    |  78.49%   |   0.689   |  52.37%  |\n",
        "|  10   | Adam-Epoches_50 |     3s     |   0.622    |  64.79%   |   0.680   |  52.78%  |\n",
        "|  11   | Adam-Epoches_50 |     3s     |   0.628    |  63.95%   |   0.616   |  65.30%  |\n",
        "|  12   | Adam-Epoches_50 |     4s     |   0.568    |  68.77%   |   0.670   |  58.34%  |\n",
        "|  13   | Adam-Epoches_50 |     3s     |   0.560    |  71.22%   |   0.638   |  68.71%  |\n",
        "|  14   | Adam-Epoches_50 |     3s     |   0.524    |  74.53%   |   0.689   |  52.42%  |\n",
        "|  15   | Adam-Epoches_50 |     3s     |   0.594    |  67.32%   |   0.608   |  65.91%  |\n",
        "|  16   | Adam-Epoches_50 |     3s     |   0.473    |  78.75%   |   0.673   |  71.56%  |\n",
        "|  17   | Adam-Epoches_50 |     3s     |   0.472    |  78.80%   |   0.662   |  70.99%  |\n",
        "|  18   | Adam-Epoches_50 |     3s     |   0.439    |  80.93%   |   0.637   |  69.01%  |\n",
        "|  19   | Adam-Epoches_50 |     4s     |   0.403    |  83.34%   |   0.613   |  71.60%  |\n",
        "|  20   | Adam-Epoches_50 |     3s     |   0.387    |  84.54%   |   0.633   |  72.26%  |\n",
        "|  21   | Adam-Epoches_50 |     3s     |   0.378    |  84.16%   |   0.626   |  72.97%  |\n",
        "|  22   | Adam-Epoches_50 |     3s     |   0.344    |  86.79%   |   0.654   |  71.24%  |\n",
        "|  23   | Adam-Epoches_50 |     3s     |   0.311    |  88.47%   |   0.627   |  72.45%  |\n",
        "|  24   | Adam-Epoches_50 |     3s     |   0.278    |  89.92%   |   0.659   |  72.04%  |\n",
        "|  25   | Adam-Epoches_50 |     3s     |   0.300    |  88.82%   |   0.683   |  71.84%  |\n",
        "|  26   | Adam-Epoches_50 |     4s     |   0.302    |  88.70%   |   0.691   |  71.12%  |\n",
        "|  27   | Adam-Epoches_50 |     3s     |   0.446    |  77.76%   |   0.598   |  70.89%  |\n",
        "|  28   | Adam-Epoches_50 |     3s     |   0.439    |  78.31%   |   0.623   |  62.62%  |\n",
        "|  29   | Adam-Epoches_50 |     3s     |   0.359    |  85.28%   |   0.619   |  73.97%  |\n",
        "|  30   | Adam-Epoches_50 |     3s     |   0.245    |  90.97%   |   0.686   |  72.21%  |\n",
        "|  31   | Adam-Epoches_50 |     3s     |   0.225    |  92.03%   |   0.656   |  75.07%  |\n",
        "|  32   | Adam-Epoches_50 |     3s     |   0.244    |  91.06%   |   0.706   |  72.52%  |\n",
        "|  33   | Adam-Epoches_50 |     4s     |   0.222    |  92.12%   |   0.680   |  74.01%  |\n",
        "|  34   | Adam-Epoches_50 |     3s     |   0.215    |  92.31%   |   0.674   |  70.72%  |\n",
        "|  35   | Adam-Epoches_50 |     3s     |   0.337    |  85.51%   |   0.669   |  70.53%  |\n",
        "|  36   | Adam-Epoches_50 |     3s     |   0.342    |  88.14%   |   0.631   |  72.86%  |\n",
        "|  37   | Adam-Epoches_50 |     3s     |   0.301    |  89.23%   |   0.789   |  71.45%  |\n",
        "|  38   | Adam-Epoches_50 |     3s     |   0.271    |  90.52%   |   0.726   |  73.39%  |\n",
        "|  39   | Adam-Epoches_50 |     3s     |   0.323    |  87.18%   |   0.747   |  71.75%  |\n",
        "|  40   | Adam-Epoches_50 |     4s     |   0.281    |  89.30%   |   0.887   |  70.57%  |\n",
        "|  41   | Adam-Epoches_50 |     3s     |   0.336    |  86.48%   |   0.663   |  67.73%  |\n",
        "|  42   | Adam-Epoches_50 |     3s     |   0.332    |  86.64%   |   0.842   |  62.40%  |\n",
        "|  43   | Adam-Epoches_50 |     3s     |   0.308    |  88.10%   |   0.707   |  72.48%  |\n",
        "|  44   | Adam-Epoches_50 |     3s     |   0.263    |  90.17%   |   0.698   |  72.53%  |\n",
        "|  45   | Adam-Epoches_50 |     3s     |   0.227    |  92.27%   |   0.665   |  66.61%  |\n",
        "|  46   | Adam-Epoches_50 |     3s     |   0.323    |  86.08%   |   0.678   |  58.02%  |\n",
        "|  47   | Adam-Epoches_50 |     4s     |   0.403    |  79.63%   |   0.761   |  69.06%  |\n",
        "|  48   | Adam-Epoches_50 |     3s     |   0.285    |  88.96%   |   0.784   |  72.67%  |\n",
        "|  49   | Adam-Epoches_50 |     3s     |   0.227    |  91.97%   |   0.779   |  73.25%  |\n",
        "|  50   | Adam-Epoches_50 |     3s     |   0.197    |  93.16%   |   0.805   |  73.18%  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20086f8c-a161-4c33-8396-e115d97345ef",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "20086f8c-a161-4c33-8396-e115d97345ef"
      },
      "source": [
        "### 3. Use Adam optimizer, 50 epochs and randomly initialized embeddings, run the experiments with the following models:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec5f761d-697b-44e9-b6d4-178755bf2d07",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "ec5f761d-697b-44e9-b6d4-178755bf2d07"
      },
      "source": [
        "#### <center>Feed Forward Neural Network </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b1c6306-4d77-4efa-aa13-e47581436d45",
      "metadata": {
        "id": "7b1c6306-4d77-4efa-aa13-e47581436d45"
      },
      "source": [
        "- One-layer feed forward neural network, hidden dimension is 500.\n",
        "- Two-layer feed forward neural network, hidden dimensions are 500 and 300.\n",
        "- Three-layer feed forward neural network, hidden dimensions are 500, 300, and 200.\n",
        "| Epoch |    Model     | Hidden | Time | Train Loss | Train Acc | Val. Loss | Val. Acc |\n",
        "| :---: | :----------: | :----: | :--: | :--------: | :-------: | :-------: | :------: |\n",
        "|   1   | OneLayerFFNN | [500]  |  4s  |   0.558    |  70.21%   |   0.449   |  79.74%  |\n",
        "|   2   | OneLayerFFNN | [500]  |  2s  |   0.354    |  84.97%   |   0.346   |  85.58%  |\n",
        "|   3   | OneLayerFFNN | [500]  |  2s  |   0.254    |  89.97%   |   0.351   |  86.18%  |\n",
        "|   4   | OneLayerFFNN | [500]  |  2s  |   0.213    |  92.57%   |   0.313   |  88.26%  |\n",
        "|   5   | OneLayerFFNN | [500]  |  2s  |   0.156    |  94.32%   |   0.407   |  86.31%  |\n",
        "|   6   | OneLayerFFNN | [500]  |  2s  |   0.148    |  95.63%   |   0.336   |  88.61%  |\n",
        "|   7   | OneLayerFFNN | [500]  |  2s  |   0.078    |  97.80%   |   0.370   |  88.33%  |\n",
        "|   8   | OneLayerFFNN | [500]  |  2s  |   0.084    |  97.75%   |   0.456   |  87.56%  |\n",
        "|   9   | OneLayerFFNN | [500]  |  2s  |   0.061    |  98.62%   |   0.436   |  88.38%  |\n",
        "|  10   | OneLayerFFNN | [500]  |  2s  |   0.053    |  98.91%   |   0.468   |  88.18%  |\n",
        "|  11   | OneLayerFFNN | [500]  |  2s  |   0.050    |  99.09%   |   0.491   |  88.06%  |\n",
        "|  12   | OneLayerFFNN | [500]  |  2s  |   0.019    |  99.62%   |   0.520   |  88.04%  |\n",
        "|  13   | OneLayerFFNN | [500]  |  2s  |   0.048    |  99.27%   |   0.589   |  87.78%  |\n",
        "|  14   | OneLayerFFNN | [500]  |  2s  |   0.054    |  99.40%   |   0.581   |  87.41%  |\n",
        "|  15   | OneLayerFFNN | [500]  |  2s  |   0.057    |  99.48%   |   0.552   |  88.05%  |\n",
        "|  16   | OneLayerFFNN | [500]  |  2s  |   0.022    |  99.57%   |   0.583   |  87.93%  |\n",
        "|  17   | OneLayerFFNN | [500]  |  3s  |   0.023    |  99.67%   |   0.594   |  87.99%  |\n",
        "|  18   | OneLayerFFNN | [500]  |  2s  |   0.003    |  99.99%   |   0.610   |  88.00%  |\n",
        "|  19   | OneLayerFFNN | [500]  |  2s  |   0.010    |  99.74%   |   0.640   |  87.99%  |\n",
        "|  20   | OneLayerFFNN | [500]  |  2s  |   0.009    |  99.78%   |   0.705   |  87.50%  |\n",
        "|  21   | OneLayerFFNN | [500]  |  2s  |   0.067    |  99.26%   |   0.681   |  87.89%  |\n",
        "|  22   | OneLayerFFNN | [500]  |  2s  |   0.031    |  99.44%   |   0.715   |  87.33%  |\n",
        "|  23   | OneLayerFFNN | [500]  |  2s  |   0.017    |  99.69%   |   0.702   |  87.90%  |\n",
        "|  24   | OneLayerFFNN | [500]  |  2s  |   0.025    |  99.58%   |   0.741   |  87.69%  |\n",
        "|  25   | OneLayerFFNN | [500]  |  2s  |   0.033    |  99.48%   |   0.731   |  87.85%  |\n",
        "|  26   | OneLayerFFNN | [500]  |  2s  |   0.034    |  99.33%   |   0.799   |  87.45%  |\n",
        "|  27   | OneLayerFFNN | [500]  |  2s  |   0.031    |  99.69%   |   0.746   |  87.91%  |\n",
        "|  28   | OneLayerFFNN | [500]  |  2s  |   0.026    |  99.62%   |   0.754   |  88.10%  |\n",
        "|  29   | OneLayerFFNN | [500]  |  2s  |   0.001    |  100.00%  |   0.762   |  88.01%  |\n",
        "|  30   | OneLayerFFNN | [500]  |  2s  |   0.001    |  100.00%  |   0.772   |  88.04%  |\n",
        "|  31   | OneLayerFFNN | [500]  |  2s  |   0.001    |  100.00%  |   0.782   |  88.00%  |\n",
        "|  32   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.794   |  87.99%  |\n",
        "|  33   | OneLayerFFNN | [500]  |  3s  |   0.000    |  100.00%  |   0.807   |  87.97%  |\n",
        "|  34   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.823   |  87.89%  |\n",
        "|  35   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.839   |  88.01%  |\n",
        "|  36   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.857   |  87.99%  |\n",
        "|  37   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.876   |  87.92%  |\n",
        "|  38   | OneLayerFFNN | [500]  |  2s  |   0.000    |  99.99%   |   0.899   |  87.91%  |\n",
        "|  39   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.911   |  87.93%  |\n",
        "|  40   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.923   |  87.93%  |\n",
        "|  41   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.935   |  87.80%  |\n",
        "|  42   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.946   |  87.85%  |\n",
        "|  43   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.958   |  87.96%  |\n",
        "|  44   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.968   |  87.95%  |\n",
        "|  45   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.981   |  87.91%  |\n",
        "|  46   | OneLayerFFNN | [500]  |  2s  |   0.000    |  100.00%  |   0.999   |  87.67%  |\n",
        "|  47   | OneLayerFFNN | [500]  |  2s  |   0.054    |  99.48%   |   1.087   |  87.59%  |\n",
        "|  48   | OneLayerFFNN | [500]  |  2s  |   0.008    |  99.79%   |   1.129   |  86.98%  |\n",
        "|  49   | OneLayerFFNN | [500]  |  3s  |   0.060    |  99.44%   |   1.196   |  86.80%  |\n",
        "|  50   | OneLayerFFNN | [500]  |  2s  |   0.001    |  99.95%   |   1.127   |  87.46%  |\n",
        "| :---: | :----------: | :--------: | :--: | :--------: | :-------: | :-------: | :------: |\n",
        "|   1   | TwoLayerFFNN | [500, 300] |  2s  |   0.549    |  71.43%   |   0.425   |  80.76%  |\n",
        "|   2   | TwoLayerFFNN | [500, 300] |  2s  |   0.357    |  84.53%   |   0.348   |  85.46%  |\n",
        "|   3   | TwoLayerFFNN | [500, 300] |  2s  |   0.252    |  89.82%   |   0.326   |  86.62%  |\n",
        "|   4   | TwoLayerFFNN | [500, 300] |  2s  |   0.185    |  92.80%   |   0.343   |  87.01%  |\n",
        "|   5   | TwoLayerFFNN | [500, 300] |  2s  |   0.137    |  95.18%   |   0.407   |  85.28%  |\n",
        "|   6   | TwoLayerFFNN | [500, 300] |  2s  |   0.093    |  97.01%   |   0.423   |  86.88%  |\n",
        "|   7   | TwoLayerFFNN | [500, 300] |  2s  |   0.064    |  97.86%   |   0.393   |  86.82%  |\n",
        "|   8   | TwoLayerFFNN | [500, 300] |  3s  |   0.053    |  98.32%   |   0.560   |  87.27%  |\n",
        "|   9   | TwoLayerFFNN | [500, 300] |  2s  |   0.024    |  99.03%   |   0.637   |  86.86%  |\n",
        "|  10   | TwoLayerFFNN | [500, 300] |  2s  |   0.019    |  99.39%   |   0.745   |  87.42%  |\n",
        "|  11   | TwoLayerFFNN | [500, 300] |  2s  |   0.065    |  98.44%   |   0.746   |  86.56%  |\n",
        "|  12   | TwoLayerFFNN | [500, 300] |  2s  |   0.032    |  98.83%   |   0.827   |  86.91%  |\n",
        "|  13   | TwoLayerFFNN | [500, 300] |  3s  |   0.025    |  99.25%   |   0.906   |  86.98%  |\n",
        "|  14   | TwoLayerFFNN | [500, 300] |  2s  |   0.036    |  99.15%   |   0.956   |  87.09%  |\n",
        "|  15   | TwoLayerFFNN | [500, 300] |  2s  |   0.016    |  99.42%   |   1.061   |  86.88%  |\n",
        "|  16   | TwoLayerFFNN | [500, 300] |  2s  |   0.020    |  99.33%   |   1.075   |  87.20%  |\n",
        "|  17   | TwoLayerFFNN | [500, 300] |  2s  |   0.018    |  99.31%   |   1.178   |  86.70%  |\n",
        "|  18   | TwoLayerFFNN | [500, 300] |  2s  |   0.026    |  99.22%   |   1.089   |  87.52%  |\n",
        "|  19   | TwoLayerFFNN | [500, 300] |  2s  |   0.006    |  99.70%   |   1.130   |  87.27%  |\n",
        "|  20   | TwoLayerFFNN | [500, 300] |  2s  |   0.011    |  99.38%   |   1.156   |  87.61%  |\n",
        "|  21   | TwoLayerFFNN | [500, 300] |  2s  |   0.005    |  99.92%   |   1.226   |  87.04%  |\n",
        "|  22   | TwoLayerFFNN | [500, 300] |  2s  |   0.018    |  99.24%   |   1.221   |  87.14%  |\n",
        "|  23   | TwoLayerFFNN | [500, 300] |  2s  |   0.018    |  99.28%   |   1.017   |  86.85%  |\n",
        "|  24   | TwoLayerFFNN | [500, 300] |  2s  |   0.008    |  99.58%   |   1.133   |  87.10%  |\n",
        "|  25   | TwoLayerFFNN | [500, 300] |  2s  |   0.010    |  99.49%   |   1.230   |  87.28%  |\n",
        "|  26   | TwoLayerFFNN | [500, 300] |  2s  |   0.009    |  99.76%   |   1.384   |  86.40%  |\n",
        "|  27   | TwoLayerFFNN | [500, 300] |  2s  |   0.013    |  99.44%   |   1.334   |  87.40%  |\n",
        "|  28   | TwoLayerFFNN | [500, 300] |  2s  |   0.008    |  99.58%   |   1.433   |  87.30%  |\n",
        "|  29   | TwoLayerFFNN | [500, 300] |  2s  |   0.008    |  99.52%   |   1.441   |  87.03%  |\n",
        "|  30   | TwoLayerFFNN | [500, 300] |  2s  |   0.018    |  99.14%   |   1.122   |  87.16%  |\n",
        "|  31   | TwoLayerFFNN | [500, 300] |  2s  |   0.008    |  99.63%   |   1.270   |  86.65%  |\n",
        "|  32   | TwoLayerFFNN | [500, 300] |  2s  |   0.017    |  99.58%   |   0.839   |  86.85%  |\n",
        "|  33   | TwoLayerFFNN | [500, 300] |  2s  |   0.008    |  99.58%   |   1.274   |  87.01%  |\n",
        "|  34   | TwoLayerFFNN | [500, 300] |  3s  |   0.014    |  99.56%   |   1.393   |  87.35%  |\n",
        "|  35   | TwoLayerFFNN | [500, 300] |  2s  |   0.006    |  99.65%   |   1.482   |  86.97%  |\n",
        "|  36   | TwoLayerFFNN | [500, 300] |  2s  |   0.031    |  99.58%   |   1.585   |  87.46%  |\n",
        "|  37   | TwoLayerFFNN | [500, 300] |  2s  |   0.004    |  99.86%   |   1.644   |  87.43%  |\n",
        "|  38   | TwoLayerFFNN | [500, 300] |  2s  |   0.064    |  99.45%   |   1.242   |  87.18%  |\n",
        "|  39   | TwoLayerFFNN | [500, 300] |  3s  |   0.011    |  99.58%   |   1.276   |  86.84%  |\n",
        "|  40   | TwoLayerFFNN | [500, 300] |  2s  |   0.009    |  99.61%   |   1.367   |  86.91%  |\n",
        "|  41   | TwoLayerFFNN | [500, 300] |  2s  |   0.021    |  99.64%   |   1.469   |  86.97%  |\n",
        "|  42   | TwoLayerFFNN | [500, 300] |  2s  |   0.009    |  99.64%   |   1.560   |  87.26%  |\n",
        "|  43   | TwoLayerFFNN | [500, 300] |  2s  |   0.009    |  99.66%   |   1.578   |  87.16%  |\n",
        "|  44   | TwoLayerFFNN | [500, 300] |  2s  |   0.006    |  99.61%   |   1.659   |  87.08%  |\n",
        "|  45   | TwoLayerFFNN | [500, 300] |  2s  |   0.010    |  99.41%   |   1.692   |  87.43%  |\n",
        "|  46   | TwoLayerFFNN | [500, 300] |  2s  |   0.003    |  99.98%   |   1.757   |  87.54%  |\n",
        "|  47   | TwoLayerFFNN | [500, 300] |  2s  |   0.031    |  99.21%   |   1.110   |  87.11%  |\n",
        "|  48   | TwoLayerFFNN | [500, 300] |  2s  |   0.007    |  99.76%   |   1.266   |  86.80%  |\n",
        "|  49   | TwoLayerFFNN | [500, 300] |  2s  |   0.034    |  99.27%   |   1.282   |  86.91%  |\n",
        "|  50   | TwoLayerFFNN | [500, 300] |  2s  |   0.006    |  99.63%   |   1.458   |  87.03%  |\n",
        "| :---: | :------------: | :-------------: | :--: | :--------: | :-------: | :-------: | :------: |\n",
        "|   1   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.541    |  72.47%   |   0.436   |  80.01%  |\n",
        "|   2   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.356    |  84.82%   |   0.365   |  84.83%  |\n",
        "|   3   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.287    |  88.43%   |   0.344   |  85.33%  |\n",
        "|   4   | ThreeLayerFFNN | [500, 300, 200] |  3s  |   0.209    |  91.99%   |   0.379   |  85.53%  |\n",
        "|   5   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.158    |  94.30%   |   0.362   |  87.40%  |\n",
        "|   6   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.108    |  96.38%   |   0.379   |  87.91%  |\n",
        "|   7   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.067    |  97.82%   |   0.495   |  87.88%  |\n",
        "|   8   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.045    |  98.73%   |   0.592   |  87.78%  |\n",
        "|   9   | ThreeLayerFFNN | [500, 300, 200] |  3s  |   0.107    |  97.22%   |   0.506   |  87.04%  |\n",
        "|  10   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.075    |  98.45%   |   0.592   |  86.59%  |\n",
        "|  11   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.019    |  99.20%   |   0.801   |  86.49%  |\n",
        "|  12   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.049    |  98.56%   |   0.826   |  87.52%  |\n",
        "|  13   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.015    |  99.30%   |   0.962   |  87.26%  |\n",
        "|  14   | ThreeLayerFFNN | [500, 300, 200] |  3s  |   0.019    |  99.45%   |   0.965   |  87.13%  |\n",
        "|  15   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.010    |  99.48%   |   1.073   |  86.65%  |\n",
        "|  16   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.022    |  99.24%   |   0.949   |  86.92%  |\n",
        "|  17   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.011    |  99.29%   |   1.082   |  87.03%  |\n",
        "|  18   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.034    |  99.24%   |   0.671   |  86.41%  |\n",
        "|  19   | ThreeLayerFFNN | [500, 300, 200] |  3s  |   0.056    |  98.64%   |   1.001   |  87.34%  |\n",
        "|  20   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.024    |  99.20%   |   0.864   |  87.58%  |\n",
        "|  21   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.008    |  99.75%   |   1.007   |  87.56%  |\n",
        "|  22   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.033    |  99.32%   |   0.935   |  81.25%  |\n",
        "|  23   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.037    |  98.73%   |   0.954   |  87.21%  |\n",
        "|  24   | ThreeLayerFFNN | [500, 300, 200] |  3s  |   0.009    |  99.51%   |   1.033   |  87.39%  |\n",
        "|  25   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.022    |  99.30%   |   0.879   |  87.63%  |\n",
        "|  26   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.009    |  99.67%   |   1.108   |  87.62%  |\n",
        "|  27   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.019    |  99.35%   |   0.833   |  86.62%  |\n",
        "|  28   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.011    |  99.45%   |   1.032   |  87.13%  |\n",
        "|  29   | ThreeLayerFFNN | [500, 300, 200] |  3s  |   0.019    |  99.26%   |   1.074   |  87.24%  |\n",
        "|  30   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.010    |  99.47%   |   1.145   |  87.27%  |\n",
        "|  31   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.007    |  99.74%   |   1.294   |  87.01%  |\n",
        "|  32   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.021    |  99.21%   |   1.182   |  86.90%  |\n",
        "|  33   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.012    |  99.39%   |   1.136   |  87.12%  |\n",
        "|  34   | ThreeLayerFFNN | [500, 300, 200] |  3s  |   0.009    |  99.49%   |   1.244   |  87.23%  |\n",
        "|  35   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.008    |  99.69%   |   1.329   |  87.48%  |\n",
        "|  36   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.015    |  99.58%   |   0.918   |  87.16%  |\n",
        "|  37   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.011    |  99.18%   |   1.134   |  86.76%  |\n",
        "|  38   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.006    |  99.58%   |   1.259   |  87.05%  |\n",
        "|  39   | ThreeLayerFFNN | [500, 300, 200] |  3s  |   0.006    |  99.63%   |   1.486   |  86.70%  |\n",
        "|  40   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.018    |  99.03%   |   1.251   |  86.81%  |\n",
        "|  41   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.019    |  99.27%   |   0.919   |  87.13%  |\n",
        "|  42   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.009    |  99.53%   |   1.082   |  87.48%  |\n",
        "|  43   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.087    |  99.12%   |   0.904   |  86.83%  |\n",
        "|  44   | ThreeLayerFFNN | [500, 300, 200] |  3s  |   0.013    |  99.48%   |   1.334   |  86.79%  |\n",
        "|  45   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.009    |  99.60%   |   1.481   |  86.83%  |\n",
        "|  46   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.015    |  99.45%   |   1.270   |  87.31%  |\n",
        "|  47   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.013    |  99.50%   |   1.079   |  87.19%  |\n",
        "|  48   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.008    |  99.61%   |   1.250   |  86.60%  |\n",
        "|  49   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.007    |  99.58%   |   1.310   |  87.04%  |\n",
        "|  50   | ThreeLayerFFNN | [500, 300, 200] |  2s  |   0.006    |  99.68%   |   1.382   |  87.56%  |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46a14acc-ba7b-43a0-ab21-f5c553d185ad",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "46a14acc-ba7b-43a0-ab21-f5c553d185ad"
      },
      "source": [
        "#### <center>CNN model</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ac6450-8df3-4f64-90ef-ba2b7697afde",
      "metadata": {
        "id": "d5ac6450-8df3-4f64-90ef-ba2b7697afde"
      },
      "source": [
        "- CNN model (using three feature maps with the sizes of feature map are 1, 2, and 3).\n",
        "\n",
        "| Epoch | Model | Kernal Size | Time | Train Loss | Train Acc | Val. Loss | Val. Acc |\n",
        "| :---: | :---: | :---------: | :--: | :--------: | :-------: | :-------: | :------: |\n",
        "|  01   |  CNN  |[1]|  9s  |   0.548    |  73.06%   |   0.423   |  81.68%  |\n",
        "|  02   |  CNN  |[1]|  8s  |   0.363    |  84.67%   |   0.347   |  84.99%  |\n",
        "|  03   |  CNN  |[1]|  9s  |   0.286    |  88.32%   |   0.323   |  86.10%  |\n",
        "|  04   |  CNN  |[1]|  8s  |   0.234    |  90.97%   |   0.310   |  86.80%  |\n",
        "|  05   |  CNN  |[1]|  8s  |   0.190    |  93.05%   |   0.323   |  86.47%  |\n",
        "|  06   |  CNN  |[1]|  8s  |   0.144    |  95.51%   |   0.308   |  87.51%  |\n",
        "|  07   |  CNN  |[1]|  8s  |   0.109    |  97.11%   |   0.310   |  87.67%  |\n",
        "|  08   |  CNN  |[1]|  8s  |   0.084    |  97.99%   |   0.318   |  87.70%  |\n",
        "|  09   |  CNN  |[1]|  8s  |   0.056    |  98.96%   |   0.329   |  87.55%  |\n",
        "|  10   |  CNN  |[1]|  8s  |   0.038    |  99.50%   |   0.343   |  87.75%  |\n",
        "|  11   |  CNN  |[1]|  8s  |   0.025    |  99.81%   |   0.361   |  87.54%  |\n",
        "|  12   |  CNN  |[1]|  8s  |   0.022    |  99.77%   |   0.373   |  87.82%  |\n",
        "|  13   |  CNN  |[1]|  8s  |   0.018    |  99.83%   |   0.386   |  87.80%  |\n",
        "|  14   |  CNN  |[1]|  8s  |   0.009    |  99.99%   |   0.401   |  87.83%  |\n",
        "|  15   |  CNN  |[1]|  8s  |   0.016    |  99.81%   |   0.409   |  87.83%  |\n",
        "|  16   |  CNN  |[1]|  8s  |   0.005    |  100.00%  |   0.422   |  87.80%  |\n",
        "|  17   |  CNN  |[1]|  8s  |   0.009    |  99.82%   |   0.430   |  87.80%  |\n",
        "|  18   |  CNN  |[1]|  8s  |   0.003    |  100.00%  |   0.442   |  87.79%  |\n",
        "|  19   |  CNN  |[1]|  8s  |   0.002    |  100.00%  |   0.454   |  87.76%  |\n",
        "|  20   |  CNN  |[1]|  8s  |   0.009    |  99.85%   |   0.463   |  87.71%  |\n",
        "|  21   |  CNN  |[1]|  8s  |   0.010    |  99.78%   |   0.468   |  87.72%  |\n",
        "|  22   |  CNN  |[1]|  9s  |   0.002    |  100.00%  |   0.478   |  87.69%  |\n",
        "|  23   |  CNN  |[1]|  7s  |   0.001    |  100.00%  |   0.489   |  87.61%  |\n",
        "|  24   |  CNN  |[1]|  8s  |   0.010    |  99.80%   |   0.491   |  87.27%  |\n",
        "|  25   |  CNN  |[1]|  9s  |   0.001    |  100.00%  |   0.500   |  87.45%  |\n",
        "|  26   |  CNN  |[1]|  9s  |   0.001    |  100.00%  |   0.507   |  87.46%  |\n",
        "|  27   |  CNN  |[1]|  8s  |   0.001    |  100.00%  |   0.516   |  87.47%  |\n",
        "|  28   |  CNN  |[1]|  8s  |   0.008    |  99.83%   |   0.611   |  85.91%  |\n",
        "|  29   |  CNN  |[1]|  8s  |   0.001    |  100.00%  |   0.529   |  87.46%  |\n",
        "|  30   |  CNN  |[1]|  8s  |   0.010    |  99.80%   |   0.528   |  87.02%  |\n",
        "|  31   |  CNN  |[1]|  8s  |   0.001    |  100.00%  |   0.535   |  87.29%  |\n",
        "|  32   |  CNN  |[1]|  8s  |   0.000    |  100.00%  |   0.543   |  87.18%  |\n",
        "|  33   |  CNN  |[1]|  8s  |   0.007    |  99.85%   |   0.536   |  87.27%  |\n",
        "|  34   |  CNN  |[1]|  8s  |   0.000    |  100.00%  |   0.545   |  87.20%  |\n",
        "|  35   |  CNN  |[1]|  8s  |   0.000    |  100.00%  |   0.551   |  87.26%  |\n",
        "|  36   |  CNN  |[1]|  8s  |   0.000    |  100.00%  |   0.558   |  87.21%  |\n",
        "|  37   |  CNN  |[1]|  9s  |   0.000    |  100.00%  |   0.564   |  87.29%  |\n",
        "|  38   |  CNN  |[1]|  8s  |   0.000    |  100.00%  |   0.570   |  87.34%  |\n",
        "|  39   |  CNN  |[1]|  8s  |   0.010    |  99.81%   |   0.584   |  86.64%  |\n",
        "|  40   |  CNN  |[1]|  8s  |   0.013    |  99.79%   |   0.575   |  86.52%  |\n",
        "|  41   |  CNN  |[1]|  9s  |   0.007    |  99.84%   |   0.568   |  86.78%  |\n",
        "|  42   |  CNN  |[1]|  8s  |   0.000    |  100.00%  |   0.576   |  86.80%  |\n",
        "|  43   |  CNN  |[1]|  8s  |   0.000    |  100.00%  |   0.582   |  86.81%  |\n",
        "|  44   |  CNN  |[1]|  8s  |   0.009    |  99.85%   |   0.580   |  86.67%  |\n",
        "|  45   |  CNN  |[1]|  8s  |   0.009    |  99.81%   |   0.575   |  86.75%  |\n",
        "|  46   |  CNN  |[1]|  8s  |   0.007    |  99.85%   |   0.567   |  86.71%  |\n",
        "|  47   |  CNN  |[1]|  9s  |   0.000    |  100.00%  |   0.574   |  86.71%  |\n",
        "|  48   |  CNN  |[1]|  8s  |   0.011    |  99.82%   |   0.562   |  86.61%  |\n",
        "|  49   |  CNN  |[1]|  8s  |   0.000    |  100.00%  |   0.572   |  86.69%  |\n",
        "|  50   |  CNN  |[1]|  8s  |   0.008    |  99.74%   |   0.595   |  86.52%  |\n",
        "|-------|-------|-------------|--------|------------|-----------|-----------|----------|\n",
        "| Epoch | Model | Kernel Size | Time   | Train Loss | Train Acc | Val. Loss | Val. Acc |\n",
        "| 01    | CNN   | [2]    | 34s | 0.551 | 72.37%    | 0.435| 80.59%   |\n",
        "| 02    | CNN   | [2]    | 34s | 0.375 | 84.14%    | 0.370| 83.37%   |\n",
        "| 03    | CNN   | [2]    | 34s | 0.290 | 88.48%    | 0.334| 85.81%   |\n",
        "| 04    | CNN   | [2]    | 34s | 0.226 | 91.75%    | 0.326| 85.94%   |\n",
        "| 05    | CNN   | [2]    | 34s | 0.167 | 94.76%    | 0.310| 86.39%   |\n",
        "| 06    | CNN   | [2]    | 34s | 0.115 | 97.07%    | 0.308| 86.69%   |\n",
        "| 07    | CNN   | [2]    | 34s | 0.076 | 98.68%    | 0.313| 87.33%   |\n",
        "| 08    | CNN   | [2]    | 34s | 0.055 | 99.29%    | 0.318| 86.98%   |\n",
        "| 09    | CNN   | [2]    | 34s | 0.031 | 99.89%    | 0.328| 87.00%   |\n",
        "| 10    | CNN   | [2]    | 34s | 0.019 | 99.97%    | 0.338| 86.93%   |\n",
        "| 11    | CNN   | [2]    | 34s | 0.017 | 99.87%    | 0.349| 87.21%   |\n",
        "| 12    | CNN   | [2]    | 34s | 0.009 | 99.99%    | 0.357| 87.18%   |\n",
        "| 13    | CNN   | [2]    | 34s | 0.011 | 99.87%    | 0.364| 87.35%   |\n",
        "| 14    | CNN   | [2]    | 34s | 0.005 | 100.00%   | 0.374| 87.34%   |\n",
        "| 15    | CNN   | [2]    | 34s | 0.011 | 99.81%    | 0.375| 87.31%   |\n",
        "| 16    | CNN   | [2]    | 34s | 0.004 | 100.00%   | 0.385| 87.45%   |\n",
        "| 17    | CNN   | [2]    | 34s | 0.012 | 99.78%    | 0.391| 87.25%   |\n",
        "| 18    | CNN   | [2]    | 34s | 0.011 | 99.79%    | 0.394| 86.94%   |\n",
        "| 19    | CNN   | [2]    | 34s | 0.011 | 99.79%    | 0.397| 87.34%   |\n",
        "| 20    | CNN   | [2]    | 34s | 0.003 | 99.99%    | 0.405| 87.54%   |\n",
        "| 21    | CNN   | [2]    | 34s | 0.009 | 99.83%    | 0.409| 87.79%   |\n",
        "| 22    | CNN   | [2]    | 34s | 0.001 | 100.00%   | 0.419| 87.78%   |\n",
        "| 23    | CNN   | [2]    | 34s | 0.001 | 100.00%   | 0.425| 87.79%   |\n",
        "| 24    | CNN   | [2]    | 34s | 0.009 | 99.80%    | 0.430| 87.46%   |\n",
        "| 25    | CNN   | [2]    | 34s | 0.009 | 99.82%    | 0.424| 87.51%   |\n",
        "| 26    | CNN   | [2]    | 34s | 0.009 | 99.81%    | 0.427| 87.57%   |\n",
        "| 27    | CNN   | [2]    | 34s | 0.001 | 100.00%   | 0.437| 87.71%   |\n",
        "| 28    | CNN   | [2]    | 34s | 0.009 | 99.82%    | 0.436| 87.35%   |\n",
        "| 29    | CNN   | [2]    | 34s | 0.001 | 100.00%   | 0.445| 87.46%   |\n",
        "| 30    | CNN   | [2]    | 34s | 0.007 | 99.83%    | 0.448| 87.31%   |\n",
        "| 31    | CNN   | [2]    | 34s | 0.001 | 100.00%   | 0.453| 87.67%   |\n",
        "| 32    | CNN   | [2]    | 34s | 0.000 | 100.00%   | 0.457| 87.67%   |\n",
        "| 33    | CNN   | [2]    | 34s | 0.000 | 100.00%   | 0.462| 87.79%   |\n",
        "| 34    | CNN   | [2]    | 34s | 0.000 | 100.00%   | 0.466| 87.84%   |\n",
        "| 35    | CNN   | [2]    | 34s | 0.000 | 100.00%   | 0.470| 87.91%   |\n",
        "| 36    | CNN   | [2]    | 34s | 0.006 | 99.81%    | 0.476| 87.78%   |\n",
        "| 37    | CNN   | [2]    | 34s | 0.009 | 99.79%    | 0.471| 87.38%   |\n",
        "| 38    | CNN   | [2]    | 34s | 0.010 | 99.77%    | 0.470| 87.55%   |\n",
        "| 39    | CNN   | [2]    | 34s | 0.000 | 100.00%   | 0.474| 87.63%   |\n",
        "| 40    | CNN   | [2]    | 34s | 0.000 | 100.00%   | 0.476| 87.63%   |\n",
        "| 41    | CNN   | [2]    | 34s | 0.012 | 99.78%    | 0.470| 87.73%   |\n",
        "| 42    | CNN   | [2]    | 34s | 0.012 | 99.72%    | 0.478| 87.71%   |\n",
        "| 43    | CNN   | [2]    | 34s | 0.000 | 100.00%   | 0.479| 87.74%   |\n",
        "| 44    | CNN   | [2]    | 34s | 0.000 | 100.00%   | 0.480| 87.74%   |\n",
        "| 45    | CNN   | [2]    | 34s | 0.000 | 100.00%   | 0.482| 87.86%   |\n",
        "| 46    | CNN   | [2]    | 34s | 0.008 | 99.83%    | 0.484| 87.26%   |\n",
        "| 47    | CNN   | [2]    | 34s | 0.007 | 99.86%    | 0.470| 87.46%   |\n",
        "| 48    | CNN   | [2]    | 34s | 0.000 | 100.00%   | 0.472| 87.52%   |\n",
        "| 49    | CNN   | [2]    | 34s | 0.000 | 100.00%   | 0.475| 87.56%   |\n",
        "| 50    | CNN   | [2]    | 34s | 0.008 | 99.80%    | 0.487| 87.50%   |\n",
        "|-------|-------|-------------|--------|------------|-----------|-----------|----------|\n",
        "| Epoch | Model | Kernel Size | Time   | Train Loss | Train Acc | Val. Loss | Val. Acc |\n",
        "| 01    | CNN   | [3]    | 54s | 0.557 | 71.69%    | 0.468| 77.52%   |\n",
        "| 02    | CNN   | [3]    | 54s | 0.384 | 83.73%    | 0.375| 83.45%   |\n",
        "| 03    | CNN   | [3]    | 54s | 0.280 | 89.37%    | 0.335| 85.32%   |\n",
        "| 04    | CNN   | [3]    | 54s | 0.205 | 93.11%    | 0.326| 85.91%   |\n",
        "| 05    | CNN   | [3]    | 53s | 0.139 | 96.35%    | 0.317| 86.38%   |\n",
        "| 06    | CNN   | [3]    | 54s | 0.087 | 98.47%    | 0.323| 86.84%   |\n",
        "| 07    | CNN   | [3]    | 54s | 0.056 | 99.39%    | 0.326| 86.88%   |\n",
        "| 08    | CNN   | [3]    | 54s | 0.031 | 99.93%    | 0.336| 87.01%   |\n",
        "| 09    | CNN   | [3]    | 54s | 0.025 | 99.77%    | 0.343| 87.12%   |\n",
        "| 10    | CNN   | [3]    | 54s | 0.013 | 100.00%   | 0.355| 87.31%   |\n",
        "| 11    | CNN   | [3]    | 54s | 0.008 | 100.00%   | 0.364| 87.34%   |\n",
        "| 12    | CNN   | [3]    | 54s | 0.006 | 100.00%   | 0.374| 87.23%   |\n",
        "| 13    | CNN   | [3]    | 54s | 0.004 | 100.00%   | 0.383| 87.34%   |\n",
        "| 14    | CNN   | [3]    | 54s | 0.009 | 99.86%    | 0.386| 87.32%   |\n",
        "| 15    | CNN   | [3]    | 54s | 0.008 | 99.89%    | 0.388| 87.21%   |\n",
        "| 16    | CNN   | [3]    | 53s | 0.013 | 99.78%    | 0.393| 87.13%   |\n",
        "| 17    | CNN   | [3]    | 54s | 0.009 | 99.85%    | 0.400| 87.30%   |\n",
        "| 18    | CNN   | [3]    | 54s | 0.011 | 99.82%    | 0.403| 87.39%   |\n",
        "| 19    | CNN   | [3]    | 54s | 0.010 | 99.80%    | 0.411| 87.16%   |\n",
        "| 20    | CNN   | [3]    | 53s | 0.010 | 99.79%    | 0.422| 86.90%   |\n",
        "| 21    | CNN   | [3]    | 54s | 0.001 | 100.00%   | 0.429| 87.05%   |\n",
        "| 22    | CNN   | [3]    | 54s | 0.009 | 99.82%    | 0.429| 87.35%   |\n",
        "| 23    | CNN   | [3]    | 54s | 0.008 | 99.83%    | 0.432| 87.08%   |\n",
        "| 24    | CNN   | [3]    | 53s | 0.001 | 100.00%   | 0.440| 87.10%   |\n",
        "| 25    | CNN   | [3]    | 54s | 0.001 | 100.00%   | 0.446| 87.21%   |\n",
        "| 26    | CNN   | [3]    | 54s | 0.017 | 99.64%    | 0.441| 87.16%   |\n",
        "| 27    | CNN   | [3]    | 54s | 0.009 | 99.81%    | 0.436| 87.58%   |\n",
        "| 28    | CNN   | [3]    | 54s | 0.001 | 100.00%   | 0.445| 87.45%   |\n",
        "| 29    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.450| 87.65%   |\n",
        "| 30    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.455| 87.65%   |\n",
        "| 31    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.460| 87.69%   |\n",
        "| 32    | CNN   | [3]    | 54s | 0.011 | 99.82%    | 0.456| 87.16%   |\n",
        "| 33    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.464| 87.50%   |\n",
        "| 34    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.466| 87.24%   |\n",
        "| 35    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.470| 87.29%   |\n",
        "| 36    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.475| 87.30%   |\n",
        "| 37    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.479| 87.41%   |\n",
        "| 38    | CNN   | [3]    | 54s | 0.009 | 99.83%    | 0.493| 87.16%   |\n",
        "| 39    | CNN   | [3]    | 54s | 0.008 | 99.83%    | 0.508| 86.96%   |\n",
        "| 40    | CNN   | [3]    | 54s | 0.012 | 99.75%    | 0.507| 87.26%   |\n",
        "| 41    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.507| 87.14%   |\n",
        "| 42    | CNN   | [3]    | 54s | 0.010 | 99.83%    | 0.495| 87.29%   |\n",
        "| 43    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.496| 87.45%   |\n",
        "| 44    | CNN   | [3]    | 54s | 0.007 | 99.85%    | 0.486| 87.41%   |\n",
        "| 45    | CNN   | [3]    | 54s | 0.008 | 99.85%    | 0.488| 87.46%   |\n",
        "| 46    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.490| 87.51%   |\n",
        "| 47    | CNN   | [3]    | 54s | 0.000 | 100.00%   | 0.493| 87.54%   |\n",
        "| 48    | CNN   | [3]    | 54s | 0.018 | 99.60%    | 0.484| 86.89%   |\n",
        "| 49    | CNN   | [3]    | 54s | 0.001 | 99.99%    | 0.478| 87.26%   |\n",
        "| 50    | CNN   | [3]    | 54s | 0.010 | 99.78%    | 0.473| 87.10%   |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f09a3f4b-d825-4b33-9bd7-e25191771da6",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "f09a3f4b-d825-4b33-9bd7-e25191771da6"
      },
      "source": [
        "#### <center>LSTM & Bi-LSTM</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bfcfbe2-c548-440f-8b65-26cdfa20f529",
      "metadata": {
        "id": "3bfcfbe2-c548-440f-8b65-26cdfa20f529"
      },
      "source": [
        "- LSTM model\n",
        "- Bi-LSTM model\n",
        "| Epoch | Model | Time | Train Loss | Train Acc | Val. Loss | Val. Acc |\n",
        "| :---: | :---: | :--: | :--------: | :-------: | :-------: | :------: |\n",
        "|  01   | LSTM  |  8s  |   0.677    |  56.81%   |   0.629   |  64.75%  |\n",
        "|  02   | LSTM  |  9s  |   0.645    |  63.10%   |   0.666   |  59.60%  |\n",
        "|  03   | LSTM  |  8s  |   0.594    |  68.82%   |   0.605   |  68.36%  |\n",
        "|  04   | LSTM  |  8s  |   0.519    |  76.13%   |   0.482   |  78.56%  |\n",
        "|  05   | LSTM  |  8s  |   0.445    |  80.36%   |   0.452   |  80.46%  |\n",
        "|  06   | LSTM  |  8s  |   0.415    |  81.71%   |   0.488   |  76.49%  |\n",
        "|  07   | LSTM  |  9s  |   0.315    |  87.45%   |   0.388   |  82.76%  |\n",
        "|  08   | LSTM  |  8s  |   0.272    |  89.36%   |   0.369   |  84.69%  |\n",
        "|  09   | LSTM  |  8s  |   0.232    |  91.32%   |   0.402   |  83.54%  |\n",
        "|  10   | LSTM  |  8s  |   0.198    |  92.82%   |   0.383   |  84.52%  |\n",
        "|  11   | LSTM  |  8s  |   0.150    |  94.58%   |   0.410   |  86.59%  |\n",
        "|  12   | LSTM  |  8s  |   0.135    |  95.34%   |   0.404   |  85.70%  |\n",
        "|  13   | LSTM  |  8s  |   0.133    |  95.29%   |   0.409   |  85.52%  |\n",
        "|  14   | LSTM  |  8s  |   0.090    |  97.01%   |   0.459   |  84.34%  |\n",
        "|  15   | LSTM  |  8s  |   0.068    |  97.87%   |   0.458   |  86.22%  |\n",
        "|  16   | LSTM  |  8s  |   0.064    |  97.97%   |   0.569   |  82.27%  |\n",
        "|  17   | LSTM  |  8s  |   0.062    |  97.91%   |   0.506   |  84.38%  |\n",
        "|  18   | LSTM  |  8s  |   0.237    |  90.36%   |   0.521   |  73.72%  |\n",
        "|  19   | LSTM  |  8s  |   0.110    |  96.11%   |   0.468   |  86.07%  |\n",
        "|  20   | LSTM  |  8s  |   0.051    |  98.38%   |   0.496   |  85.75%  |\n",
        "|  21   | LSTM  |  8s  |   0.040    |  98.78%   |   0.516   |  86.41%  |\n",
        "|  22   | LSTM  |  8s  |   0.035    |  98.93%   |   0.581   |  86.97%  |\n",
        "|  23   | LSTM  |  8s  |   0.031    |  99.11%   |   0.591   |  84.92%  |\n",
        "|  24   | LSTM  |  8s  |   0.034    |  99.14%   |   0.526   |  86.80%  |\n",
        "|  25   | LSTM  |  8s  |   0.017    |  99.44%   |   0.583   |  86.83%  |\n",
        "|  26   | LSTM  |  8s  |   0.034    |  98.96%   |   0.555   |  85.92%  |\n",
        "|  27   | LSTM  |  8s  |   0.029    |  99.08%   |   0.677   |  86.37%  |\n",
        "|  28   | LSTM  |  8s  |   0.038    |  98.82%   |   0.699   |  85.08%  |\n",
        "|  29   | LSTM  |  8s  |   0.024    |  99.27%   |   0.588   |  85.71%  |\n",
        "|  30   | LSTM  |  8s  |   0.023    |  99.29%   |   0.591   |  85.70%  |\n",
        "|  31   | LSTM  |  8s  |   0.018    |  99.34%   |   0.629   |  86.49%  |\n",
        "|  32   | LSTM  |  8s  |   0.015    |  99.50%   |   0.665   |  85.52%  |\n",
        "|  33   | LSTM  |  8s  |   0.017    |  99.48%   |   0.702   |  84.40%  |\n",
        "|  34   | LSTM  |  8s  |   0.024    |  99.19%   |   0.936   |  82.06%  |\n",
        "|  35   | LSTM  |  8s  |   0.038    |  98.75%   |   0.626   |  85.44%  |\n",
        "|  36   | LSTM  |  8s  |   0.014    |  99.52%   |   0.832   |  85.42%  |\n",
        "|  37   | LSTM  |  8s  |   0.032    |  99.15%   |   0.593   |  85.96%  |\n",
        "|  38   | LSTM  |  8s  |   0.011    |  99.61%   |   0.669   |  86.01%  |\n",
        "|  39   | LSTM  |  8s  |   0.019    |  99.52%   |   0.653   |  86.89%  |\n",
        "|  40   | LSTM  |  8s  |   0.022    |  99.28%   |   0.646   |  86.26%  |\n",
        "|  41   | LSTM  |  8s  |   0.019    |  99.42%   |   0.694   |  86.42%  |\n",
        "|  42   | LSTM  |  8s  |   0.014    |  99.53%   |   0.663   |  86.29%  |\n",
        "|  43   | LSTM  |  8s  |   0.006    |  99.72%   |   0.735   |  86.75%  |\n",
        "|  44   | LSTM  |  8s  |   0.021    |  99.31%   |   0.667   |  86.41%  |\n",
        "|  45   | LSTM  |  8s  |   0.030    |  99.09%   |   0.647   |  85.79%  |\n",
        "|  46   | LSTM  |  8s  |   0.009    |  99.61%   |   0.719   |  85.68%  |\n",
        "|  47   | LSTM  |  8s  |   0.009    |  99.62%   |   0.717   |  86.73%  |\n",
        "|  48   | LSTM  |  8s  |   0.028    |  99.17%   |   0.603   |  86.37%  |\n",
        "|  49   | LSTM  |  8s  |   0.008    |  99.70%   |   0.680   |  86.27%  |\n",
        "|  50   | LSTM  |  8s  |   0.018    |  99.43%   |   0.659   |  86.68%  |\n",
        "| :---: | :-----: | :--: | :--------: | :-------: | :-------: | :------: |\n",
        "|   1   | Bi-LSTM | 14s  |   0.671    |  58.14%   |   0.645   |  63.70%  |\n",
        "|   2   | Bi-LSTM | 15s  |   0.610    |  67.53%   |   0.585   |  68.71%  |\n",
        "|   3   | Bi-LSTM | 15s  |   0.524    |  74.39%   |   0.525   |  73.96%  |\n",
        "|   4   | Bi-LSTM | 15s  |   0.424    |  80.36%   |   0.568   |  70.38%  |\n",
        "|   5   | Bi-LSTM | 15s  |   0.347    |  84.82%   |   0.483   |  78.30%  |\n",
        "|   6   | Bi-LSTM | 15s  |   0.304    |  87.28%   |   0.400   |  82.83%  |\n",
        "|   7   | Bi-LSTM | 15s  |   0.237    |  90.22%   |   0.402   |  83.43%  |\n",
        "|   8   | Bi-LSTM | 15s  |   0.170    |  93.40%   |   0.431   |  83.21%  |\n",
        "|   9   | Bi-LSTM | 15s  |   0.134    |  95.07%   |   0.457   |  83.76%  |\n",
        "|  10   | Bi-LSTM | 15s  |   0.088    |  96.88%   |   0.464   |  85.24%  |\n",
        "|  11   | Bi-LSTM | 15s  |   0.065    |  97.84%   |   0.523   |  85.45%  |\n",
        "|  12   | Bi-LSTM | 15s  |   0.053    |  98.19%   |   0.560   |  84.70%  |\n",
        "|  13   | Bi-LSTM | 15s  |   0.035    |  98.79%   |   0.600   |  85.23%  |\n",
        "|  14   | Bi-LSTM | 15s  |   0.030    |  99.03%   |   0.641   |  84.26%  |\n",
        "|  15   | Bi-LSTM | 15s  |   0.020    |  99.27%   |   0.666   |  84.08%  |\n",
        "|  16   | Bi-LSTM | 14s  |   0.045    |  98.55%   |   0.645   |  84.21%  |\n",
        "|  17   | Bi-LSTM | 15s  |   0.023    |  99.33%   |   0.707   |  84.48%  |\n",
        "|  18   | Bi-LSTM | 15s  |   0.011    |  99.53%   |   0.815   |  84.16%  |\n",
        "|  19   | Bi-LSTM | 14s  |   0.009    |  99.65%   |   0.807   |  85.49%  |\n",
        "|  20   | Bi-LSTM | 15s  |   0.009    |  99.65%   |   0.850   |  85.36%  |\n",
        "|  21   | Bi-LSTM | 15s  |   0.026    |  99.12%   |   0.691   |  82.57%  |\n",
        "|  22   | Bi-LSTM | 15s  |   0.024    |  99.26%   |   0.712   |  83.67%  |\n",
        "|  23   | Bi-LSTM | 15s  |   0.026    |  99.29%   |   0.763   |  84.81%  |\n",
        "|  24   | Bi-LSTM | 15s  |   0.012    |  99.54%   |   0.809   |  84.59%  |\n",
        "|  25   | Bi-LSTM | 15s  |   0.007    |  99.71%   |   0.899   |  83.73%  |\n",
        "|  26   | Bi-LSTM | 15s  |   0.005    |  99.77%   |   0.903   |  84.09%  |\n",
        "|  27   | Bi-LSTM | 15s  |   0.005    |  99.74%   |   0.889   |  84.56%  |\n",
        "|  28   | Bi-LSTM | 14s  |   0.008    |  99.75%   |   0.875   |  84.21%  |\n",
        "|  29   | Bi-LSTM | 15s  |   0.017    |  99.53%   |   0.851   |  84.05%  |\n",
        "|  30   | Bi-LSTM | 15s  |   0.004    |  99.77%   |   0.942   |  84.34%  |\n",
        "|  31   | Bi-LSTM | 15s  |   0.004    |  99.77%   |   1.017   |  84.76%  |\n",
        "|  32   | Bi-LSTM | 15s  |   0.040    |  98.78%   |   0.729   |  82.28%  |\n",
        "|  33   | Bi-LSTM | 15s  |   0.027    |  99.07%   |   0.761   |  83.60%  |\n",
        "|  34   | Bi-LSTM | 15s  |   0.016    |  99.50%   |   0.766   |  84.42%  |\n",
        "|  35   | Bi-LSTM | 15s  |   0.005    |  99.79%   |   0.811   |  84.31%  |\n",
        "|  36   | Bi-LSTM | 15s  |   0.017    |  99.57%   |   0.784   |  84.07%  |\n",
        "|  37   | Bi-LSTM | 15s  |   0.015    |  99.56%   |   0.785   |  84.89%  |\n",
        "|  38   | Bi-LSTM | 15s  |   0.007    |  99.70%   |   0.908   |  84.67%  |\n",
        "|  39   | Bi-LSTM | 14s  |   0.016    |  99.43%   |   0.776   |  81.33%  |\n",
        "|  40   | Bi-LSTM | 15s  |   0.013    |  99.62%   |   0.802   |  84.84%  |\n",
        "|  41   | Bi-LSTM | 15s  |   0.018    |  99.48%   |   0.820   |  83.69%  |\n",
        "|  42   | Bi-LSTM | 15s  |   0.004    |  99.81%   |   0.885   |  84.38%  |\n",
        "|  43   | Bi-LSTM | 15s  |   0.013    |  99.50%   |   0.758   |  83.79%  |\n",
        "|  44   | Bi-LSTM | 15s  |   0.004    |  99.78%   |   0.886   |  84.26%  |\n",
        "|  45   | Bi-LSTM | 15s  |   0.003    |  99.82%   |   0.909   |  85.10%  |\n",
        "|  46   | Bi-LSTM | 14s  |   0.003    |  99.78%   |   0.929   |  85.05%  |\n",
        "|  47   | Bi-LSTM | 15s  |   0.021    |  99.33%   |   0.821   |  83.47%  |\n",
        "|  48   | Bi-LSTM | 15s  |   0.008    |  99.66%   |   0.900   |  82.55%  |\n",
        "|  49   | Bi-LSTM | 15s  |   0.011    |  99.54%   |   0.793   |  84.97%  |\n",
        "|  50   | Bi-LSTM | 15s  |   0.004    |  99.83%   |   0.824   |  85.23%  |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}